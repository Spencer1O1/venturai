Dashboard AI Chatbot Spec (Convex + Zod)
0. Summary

We will add an AI chatbot to the dashboard that lets users ask natural-language questions about their organization’s assets/reports and receive:

a short natural-language answer

structured UI renderables (tables/stats/links/charts)

grounded results based on actual database queries

Critical design rule: The LLM never queries the DB directly. The LLM outputs a strict JSON “query plan” from a small allowlisted set of operations. The server validates, authorizes, executes via Convex queries, then asks the model to summarize/render.

1) Goals & Non-Goals
Goals (v1)

Read-only Q&A over org data:

Reports (issues/incidents/maintenance reports)

Assets

Maintenance groups / assignees (if present)

Safe by construction:

Org scoping enforced server-side

Role-based field visibility enforced server-side

Query complexity limits enforced server-side

UI-first responses:

Tables / stat cards / charts / deep links

Conversation memory within a conversation:

Follow-up questions like “what about last week?” or “open the first one”

Non-Goals (v1)

Geofencing (not in your model)

Write actions (create/assign/close) — defer to v1.5

Arbitrary SQL or arbitrary joins generated by the model

“General knowledge” chatbot. This is a dashboard assistant.

2) UX Requirements (Dashboard)
Entry points

Global “Ask AI” button in top nav

Contextual: on Reports page / Asset detail page, open chat with context

Chat UI

Message list with streaming assistant text

Suggested prompts (chips)

Results panel supports renderables:

statCards

table

chart (time series)

linkList (“Open in dashboard”)

“Citations” line: Based on: Reports (12), Assets (3) (IDs internally, not necessarily shown)

Context injection

When chat is opened from a page, include:

pageKind: "reports" | "asset" | "dashboard" | ...

selectedAssetId?

selectedReportId?

activeFilters? (e.g., status=open, dateRange=30d) if applicable

Clarification behavior

If user intent requires an entity and none is provided:

ask one clarifying question with up to 5 choices

If ambiguous time (“recent”):

default to last 30 days (no clarification)

If multiple assets match:

return a clarification with top matches

3) Data & Access Model Assumptions

Your schema will differ, but the spec assumes:

Every row is scoped to an orgId

Users have a role in an org (viewer|maintainer|admin)

Reports reference assets and possibly assignees/groups

Example tables (conceptual)

orgs

users

assets { orgId, name, assetTagId/externalId, location fields, ... }

reports { orgId, assetId, status, priority, categoryId, summary, description, createdAt, updatedAt, assignedGroupId?, assignedUserId? }

maintenanceGroups { orgId, name }

4) Architecture
High-level flow

Client sends message + context → aiChat:sendMessage (Convex action)

Action calls LLM to produce Query Plan JSON

Server validates Query Plan with Zod

Server authorizes & rewrites plan (force orgId, enforce caps)

Server executes one or more Convex queries (via internal queries)

Server sends tool results back to LLM to generate:

assistant text

renderables JSON

Server validates renderables JSON with Zod

Persist messages + renderables + sources

Return response to client (streaming optional)

Key principle: allowlisted operations

The model can only request from a small list of ops.

5) Convex API Surface
Public (client-callable)

aiChat:listConversations

aiChat:getConversation

aiChat:sendMessage (action)

aiChat:rateMessage (feedback)

Internal (server-only)

internal.aiChatQueries.* for each allowed op

internal.aiChatAuth.* helpers

6) Conversation & Message Storage
aiConversations

Fields:

orgId: Id<"orgs">

createdBy: Id<"users">

createdAt: number

updatedAt: number

title: string (optional; can be auto-generated)

contextSnapshot?: { pageKind, selectedAssetId, selectedReportId, activeFilters }

isArchived?: boolean

Indexes:

by orgId + updatedAt

by createdBy + updatedAt

aiMessages

Fields:

orgId

conversationId

role: "user" | "assistant" | "system"

text: string

createdAt

renderables?: Renderables (only for assistant)

sources?: SourceRefs (assistant; internal IDs)

queryPlan?: AIQueryPlan (assistant; internal/debug)

error?: { code, message } (assistant, if something failed)

feedback?: { rating: 1|-1, reason?: string }

Indexes:

by conversationId + createdAt

by orgId + createdAt

Retention:

Keep last N messages (e.g. 200) per conversation OR archive old conversations

Never store raw model/system prompts in DB (store minimal debug info)

7) AI Query Plan Spec (JSON output #1)
Purpose

The LLM outputs a Query Plan describing what data it needs, using only allowlisted operations.

Shape

Either:

kind: "query"

ops: AIQueryOp[]

finalGoal?: string (optional model self-summary)

Or:

kind: "clarify"

question: string

choices?: { label: string; value: string }[]

Zod schema (example)
import { z } from "zod";

const DateRangePreset = z.enum(["7d", "30d", "90d", "365d", "all"]);
const SortDir = z.enum(["asc", "desc"]);

const ReportsStatus = z.enum(["open", "in_progress", "blocked", "resolved", "closed"]);
const Priority = z.enum(["Low", "Medium", "High", "Emergency"]);

const OpCommon = z.object({
  opId: z.string().min(1),          // correlate op results
  op: z.string().min(1),            // discriminator
});

const ReportsSearchArgs = z.object({
  assetId: z.string().optional(),
  status: ReportsStatus.optional(),
  priority: Priority.optional(),
  prioritiesIn: z.array(Priority).max(4).optional(),
  createdAfter: z.string().datetime().optional(),
  createdBefore: z.string().datetime().optional(),
  datePreset: DateRangePreset.optional(),
  assignedGroupId: z.string().optional(),
  assignedUserId: z.string().optional(),
  categoryId: z.string().optional(),
  text: z.string().max(200).optional(),       // text search over summary/description
  limit: z.number().int().min(1).max(50).default(20),
  sortBy: z.enum(["createdAt", "updatedAt", "priority"]).default("createdAt"),
  sortDir: SortDir.default("desc"),
}).strict();

const ReportsAggregateArgs = z.object({
  groupBy: z.enum(["status", "priority", "category", "assignedGroup", "asset"]),
  datePreset: DateRangePreset.default("30d"),
  status: ReportsStatus.optional(),
  limit: z.number().int().min(1).max(20).default(10), // top N buckets
}).strict();

const AssetsSearchArgs = z.object({
  text: z.string().max(200).optional(), // name/externalId search
  limit: z.number().int().min(1).max(25).default(10),
  sortBy: z.enum(["name", "updatedAt", "createdAt"]).default("name"),
  sortDir: SortDir.default("asc"),
}).strict();

const AssetsGetArgs = z.object({
  assetId: z.string(),
}).strict();

const ReportsGetArgs = z.object({
  reportId: z.string(),
}).strict();

const TimelineArgs = z.object({
  metric: z.enum(["reportsCreated", "reportsResolved", "openReports"]),
  datePreset: DateRangePreset.default("30d"),
  bucket: z.enum(["day", "week"]).default("day"),
  status: ReportsStatus.optional(),
}).strict();

const AIQueryOp = z.discriminatedUnion("op", [
  OpCommon.extend({ op: z.literal("reports.search"), args: ReportsSearchArgs }),
  OpCommon.extend({ op: z.literal("reports.aggregate"), args: ReportsAggregateArgs }),
  OpCommon.extend({ op: z.literal("reports.get"), args: ReportsGetArgs }),
  OpCommon.extend({ op: z.literal("assets.search"), args: AssetsSearchArgs }),
  OpCommon.extend({ op: z.literal("assets.get"), args: AssetsGetArgs }),
  OpCommon.extend({ op: z.literal("reports.timeline"), args: TimelineArgs }),
]);

export const AIQueryPlanSchema = z.union([
  z.object({
    kind: z.literal("query"),
    ops: z.array(AIQueryOp).min(1).max(3), // hard cap ops per turn
    finalGoal: z.string().max(200).optional(),
  }).strict(),
  z.object({
    kind: z.literal("clarify"),
    question: z.string().min(5).max(240),
    choices: z.array(z.object({
      label: z.string().max(60),
      value: z.string().max(120),
    })).max(5).optional(),
  }).strict(),
]);

Hard cap ops/turn keeps cost and complexity bounded and avoids “LLM tries 12 queries”.

8) Authorization & Policy Enforcement
Server must enforce (never trust LLM)

Force orgId from auth context

Enforce role-based field visibility

Enforce caps:

limit max

date range presets only (or clamp ISO dates)

Reject disallowed filters per role:

Example: viewers can’t query by assignedUser if you treat that as sensitive

Apply index-friendly constraints (optional but recommended)

Auth helper spec

getAuthContext() returns { userId, orgId, role }

All internal query fns accept { orgId, role, ...args } and enforce:

Field-level redaction:

Viewer: hide description raw text? (optional)

Maintainer/Admin: include more details

Example returned report shape (safe subset):

id, assetId, status, priority, summary, createdAt, updatedAt, categoryName, assignedGroupName

9) Operation Registry & Execution
Registry contract

Each op has:

schema (Zod args)

execute(ctx, args) → returns bounded data

resultSchema (Zod) for validating tool result shape

uiHints (optional)

Tool result shape (returned to model)

Keep it compact and structured:

type ToolResult =
  | { opId: string; op: string; ok: true; data: unknown; meta?: { truncated?: boolean } }
  | { opId: string; op: string; ok: false; error: { code: string; message: string } };
Execution rules

Execute ops sequentially in the order returned

If an op fails validation/authorization:

stop and return assistant error message (and optionally ask user to rephrase)

10) LLM Prompting Rules
System message (core policy)

Must only use information from tool results

Must not invent IDs or counts

Must ask clarification when necessary

Must produce JSON that matches schema exactly (no extra fields)

Two-step LLM calls (recommended)

Plan call: produce AIQueryPlan JSON

Answer call: given tool results, produce AIAnswer JSON (text + renderables)

This makes validation and reliability far better than “one call does everything”.

11) AI Answer Spec (JSON output #2)
Shape

text: string (concise)

renderables: Renderable[] (optional, max 3)

followups: string[] (optional, max 4)

sources: { kind: string; ids: string[] }[] (optional, for internal traceability)

confidence: number (0..1)

Renderables
const TableRenderable = z.object({
  type: z.literal("table"),
  title: z.string().max(80),
  columns: z.array(z.object({
    key: z.string().max(40),
    label: z.string().max(40),
  })).min(2).max(8),
  rows: z.array(z.record(z.union([z.string(), z.number(), z.boolean(), z.null()]))).max(50),
  primaryAction: z.object({
    label: z.string().max(30),
    kind: z.enum(["openReport", "openAsset"]),
    idKey: z.string(), // row field containing the id
  }).optional(),
}).strict();

const StatRenderable = z.object({
  type: z.literal("statCards"),
  title: z.string().max(80).optional(),
  stats: z.array(z.object({
    label: z.string().max(40),
    value: z.union([z.string(), z.number()]),
  })).min(1).max(6),
}).strict();

const ChartRenderable = z.object({
  type: z.literal("chart"),
  title: z.string().max(80),
  chartType: z.enum(["line"]),
  xKey: z.string(),
  yKey: z.string(),
  points: z.array(z.object({
    x: z.string(), // ISO date or bucket label
    y: z.number(),
  })).max(365),
}).strict();

const LinkListRenderable = z.object({
  type: z.literal("linkList"),
  title: z.string().max(80),
  links: z.array(z.object({
    label: z.string().max(80),
    kind: z.enum(["openReport", "openAsset"]),
    id: z.string(),
  })).max(10),
}).strict();

export const AIAnswerSchema = z.object({
  text: z.string().min(1).max(1200),
  renderables: z.array(z.union([
    TableRenderable,
    StatRenderable,
    ChartRenderable,
    LinkListRenderable,
  ])).max(3).optional(),
  followups: z.array(z.string().max(120)).max(4).optional(),
  sources: z.array(z.object({
    kind: z.string().max(30),
    ids: z.array(z.string()).max(50),
  })).max(6).optional(),
  confidence: z.number().min(0).max(1).optional(),
}).strict();
12) Convex Function Specs
aiChat:sendMessage (action)

Inputs

conversationId?: Id<"aiConversations">

text: string

uiContext?: { pageKind: string; selectedAssetId?: Id<"assets">; selectedReportId?: Id<"reports">; activeFilters?: any }

Steps

auth: get { userId, orgId, role }

upsert conversation:

if no conversationId, create new

insert user message

load last N messages for context (e.g. 12)

call LLM “plan” → JSON

validate with AIQueryPlanSchema

if clarify:

insert assistant message (question + choices as renderable maybe)

return

else execute ops:

authorizeAndRewritePlan(ctx, plan) (force orgId, clamp limits)

call internal queries for each op

call LLM “answer” with tool results

validate with AIAnswerSchema

insert assistant message with text + renderables + sources + debug fields

return assistant message payload

Outputs

assistant message record (or a DTO for client)

Failure modes

invalid plan JSON → assistant error + “Try rephrasing”

unauthorized op → assistant error (permission-safe)

query too broad → assistant suggests narrower filters

LLM answer invalid JSON → fallback: show minimal text response without renderables

aiChat:getConversation (query)

returns conversation + last messages (paged)

aiChat:listConversations (query)

returns recent conversations for org/user

aiChat:rateMessage (mutation)

store thumbs up/down + optional reason

13) Internal Query Implementations (Examples)

Each allowed op maps to a single internal query:

internal.aiChatQueries.reportsSearch

internal.aiChatQueries.reportsAggregate

internal.aiChatQueries.reportsGet

internal.aiChatQueries.assetsSearch

internal.aiChatQueries.assetsGet

internal.aiChatQueries.reportsTimeline

Each internal query:

requires orgId from ctx param

enforces org scoping

returns safe, bounded fields

Important: even internal queries should not accept orgId from the model; only from the orchestrator ctx.

14) Performance Constraints

Limit tool ops per user message: max 3

Max returned rows per op: 50

Max conversation context included: last 12 messages

Use indexes for common searches:

reports by orgId + createdAt

reports by orgId + status + createdAt

assets by orgId + name

Prefer aggregations over returning huge lists

15) Security & Privacy

No cross-org leakage: enforce orgId on every query

Field-level redaction based on role

Don’t include raw locations/PII unless explicitly permitted

Never store:

OpenAI API keys in db

Full prompt templates in db

Log safely: sanitize free-text inputs if you store logs elsewhere

16) Observability & Quality
Logging (server)

Store per assistant message (debug fields):

planOps: list of ops called

opDurationsMs

resultCounts

truncated: boolean

User feedback loop

thumbs up/down

optional tags (wrong data / confusing / slow / permissions)

Golden tests (recommended)

Create a small suite of fixed prompts → expected op selection:

“open reports last 7 days”

“top 5 assets by open issues”

“reports for asset X”
Run in CI with a mocked “planner” or snapshot tests for plan validation.

17) v1 Operation Set (Final)

Minimum useful operations:

assets.search

assets.get

reports.search

reports.get

reports.aggregate (groupBy status/priority/asset)

reports.timeline (created/resolved/open counts)

Everything else can wait.

18) Optional v1.1 Enhancements

“explain report priority” (derive from fields; no extra AI)

“summarize asset history” (use last N reports for asset)

cached aggregates for speed

Implementation Notes (Convex + Zod)
Where code should live (suggested)

convex/aiChat.ts (public functions: list/get/send/rate)

convex/aiChat/internalQueries.ts (internal query ops)

convex/aiChat/schemas.ts (Zod schemas)

convex/aiChat/llm.ts (planner + answerer prompts)

convex/aiChat/opRegistry.ts (op mapping + execution)

Don’t do

Don’t let the LLM specify table names

Don’t let the LLM request arbitrary fields

Don’t pass entire rows of text blobs unless needed (truncate)